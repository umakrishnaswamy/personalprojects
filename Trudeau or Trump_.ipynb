{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trudeau or Trump?\n",
    "## Using Naive Bayes to classify tweets as written by either Trump or Trudeau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was inspired by the DataCamp project \"Who's Tweeting? Trump or Trudeau\" project that taught me how to apply Naive Bayes to classifying text. Skills I learned in this project were vectorization and Naive Bayes. The dataset is from the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'author', 'status'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>I will be making a major statement from the @W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Just arrived at #ASEAN50 in the Philippines fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>After my tour of Asia, all Countries dealing w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Great to see @RandPaul looking well and back o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Excited to be heading home to see the House pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           author                                             status\n",
       "0   1  Donald J. Trump  I will be making a major statement from the @W...\n",
       "1   2  Donald J. Trump  Just arrived at #ASEAN50 in the Philippines fo...\n",
       "2   3  Donald J. Trump  After my tour of Asia, all Countries dealing w...\n",
       "3   4  Donald J. Trump  Great to see @RandPaul looking well and back o...\n",
       "4   5  Donald J. Trump  Excited to be heading home to see the House pa..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "tweet_df = pd.read_csv('tweets.csv')\n",
    "display(tweet_df.head(), print(tweet_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data has been collected via the Twitter API and not split into test and training sets, we'll need to split it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target\n",
    "y = tweet_df['author']\n",
    "\n",
    "# Split training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweet_df['status'],y,test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training and testing data all set up, but we need to create vectorized representations of the tweets in order to apply our naive bayes model. I am going to try both vectorizing by count as well as tfidf (term frequency-inverse document frequency) to see which provides more accurate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize count vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english', \n",
    "                                   min_df=0.05, max_df=0.9)\n",
    "\n",
    "# Create count train and test variables\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tfidf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                                   min_df=0.05, max_df=0.9)\n",
    "# Create tfidf train and test variables\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes Tfidf Score:  0.803030303030303\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting Multinomial Naive Bayes Model with tfidf data\n",
    "tfidf_nb = MultinomialNB()\n",
    "tfidf_nb.fit(tfidf_train, y_train)\n",
    "tfidf_nb_pred = tfidf_nb.predict(tfidf_test)\n",
    "\n",
    "# Prediction Accurary\n",
    "tfidf_nb_score = metrics.accuracy_score(y_test, tfidf_nb_pred)\n",
    "print('NaiveBayes Tfidf Score: ', tfidf_nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes Count Score:  0.7954545454545454\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting Naive Bayes Model\n",
    "count_nb = MultinomialNB()\n",
    "count_nb.fit(count_train, y_train)\n",
    "count_nb_pred = count_nb.predict(count_test)\n",
    "\n",
    "# Prediction Accurary\n",
    "count_nb_score = metrics.accuracy_score(y_test, count_nb_pred)\n",
    "print('NaiveBayes Count Score: ', count_nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nb_cm = metrics.confusion_matrix(y_test, tfidf_nb_pred, labels=['Donald J. Trump', 'Justin Trudeau'])\n",
    "count_nb_cm = metrics.confusion_matrix(y_test, count_nb_pred, labels=['Donald J. Trump', 'Justin Trudeau'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Confusion Matrix: [[56  2]\n",
      " [24 50]]\n"
     ]
    }
   ],
   "source": [
    "print('TFIDF Confusion Matrix:', tfidf_nb_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
